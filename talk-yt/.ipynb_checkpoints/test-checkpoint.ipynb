{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace YOUR_YOUTUBE_URL with the URL of the YouTube video you want to transcribe\n",
    "YOUTUBE_URL = 'https://www.youtube.com/watch?v=9nVL9nSix1A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from pytube import YouTube\n",
    "import moviepy.editor as mp\n",
    "\n",
    "# Download the video using pytube\n",
    "youtube = YouTube(YOUTUBE_URL)\n",
    "video = youtube.streams.get_audio_only()\n",
    "video.download(output_path=\"./\", filename=\"audio.mp4\")\n",
    "\n",
    "# Convert the downloaded video to WAV format using moviepy\n",
    "clip = mp.AudioFileClip(\"audio.mp4\")\n",
    "clip.write_audiofile(\"audio.wav\")\n",
    "\n",
    "# Clean up the temporary video file\n",
    "clip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading model base.en. It may take a while...whisper_init_from_file_no_state: loading model from '/Users/robertkim/.local/share/whispercpp/ggml-base.en.bin'\n",
      "whisper_model_load: loading model\n",
      "whisper_model_load: n_vocab       = 51864\n",
      "whisper_model_load: n_audio_ctx   = 1500\n",
      "whisper_model_load: n_audio_state = 512\n",
      "whisper_model_load: n_audio_head  = 8\n",
      "whisper_model_load: n_audio_layer = 6\n",
      "whisper_model_load: n_text_ctx    = 448\n",
      "whisper_model_load: n_text_state  = 512\n",
      "whisper_model_load: n_text_head   = 8\n",
      "whisper_model_load: n_text_layer  = 6\n",
      "whisper_model_load: n_mels        = 80\n",
      "whisper_model_load: f16           = 1\n",
      "whisper_model_load: type          = 2\n",
      "whisper_model_load: mem required  =  215.00 MB (+    6.00 MB per decoder)\n",
      "whisper_model_load: adding 1607 extra tokens\n",
      "whisper_model_load: model ctx     =  140.60 MB\n",
      "whisper_model_load: model size    =  140.54 MB\n",
      "whisper_init_state: kv self size  =    5.25 MB\n",
      "whisper_init_state: kv cross size =   17.58 MB\n"
     ]
    }
   ],
   "source": [
    "from whispercpp import Whisper\n",
    "\n",
    "w = Whisper.from_pretrained(\"base.en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    y, _ = (\n",
    "        ffmpeg.input(\"./audio.wav\", threads=0)\n",
    "        .output(\"-\", format=\"s16le\", acodec=\"pcm_s16le\", ac=1, ar=16000)\n",
    "        .run(\n",
    "            cmd=[\"ffmpeg\", \"-nostdin\"], capture_stdout=True, capture_stderr=True\n",
    "        )\n",
    "    )\n",
    "except ffmpeg.Error as e:\n",
    "    raise RuntimeError(f\"Failed to load audio: {e.stderr.decode()}\") from e\n",
    "\n",
    "arr = np.frombuffer(y, np.int16).flatten().astype(np.float32) / 32768.0\n",
    "\n",
    "t = w.transcribe(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The video's point is that the pursuit of happiness as we understand it is misguided and often leads to negative consequences, and instead we should focus on living well given our own unique circumstances, which leads to true happiness or eudaimonia.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "system_msg = f\"\"\"\n",
    "Pretend you are the youtuber. You made a youtube video. Here is the transcript of that video:\n",
    "\n",
    "<transcript>\n",
    "{t}\n",
    "</transcript>\n",
    "\n",
    "Now your sole goal is to answer user's questions about that video.\n",
    "\"\"\"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": \"Can you summarize the point of the video in one sentence\"},\n",
    "        ]\n",
    ")\n",
    "\n",
    "result = ''\n",
    "for choice in response.choices:\n",
    "    result += choice.message.content\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
